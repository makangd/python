{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Point Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/g2084.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial point pattern analysis is the evaluation of the pattern, or distribution, of a set of points in geographical space. Objective of point pattern analysis.The idea is to find and explain structures in our data\n",
    "\n",
    "A point pattern dataset gives the locations of an objects/observation occurring in a particular study region.\n",
    "\n",
    "Objective of point pattern analysis can be for example,\n",
    "\n",
    "- Are event locations random?\n",
    "- If not are there underlying processes which generated the pattern?\n",
    "- Do different types of points have a relationship to each other?\n",
    "- Can we develop a model that explains the patterns in our data?\n",
    "\n",
    "\n",
    "**Points and Event Points**\n",
    "\n",
    "To start we consider a series of point locations, $(s_1,s_2,…,s_n)$\n",
    "in a study region R. We limit our focus here to a two-dimensional space so that $s_j=(x_j,y_j)$ is the spatial coordinate pair for point location $j$\n",
    "\n",
    "We will be interested in two different types of points.\n",
    "\n",
    "**Event Points**\n",
    "\n",
    "Event Points are locations where something of interest has occurred. The term event is very general here and could be used to represent a wide variety of phenomena. Some examples include:\n",
    "\n",
    "- locations of individual plants of a certain species\n",
    "- archeological sites\n",
    "- addresses of disease cases\n",
    "- locations of crimes\n",
    "- the distribution of neurons\n",
    "- ...\n",
    "\n",
    "\n",
    "It is important to recognize that in the statistical analysis of point patterns the interest extends beyond the observed point pattern at hand. The observed patterns are viewed as realizations from some underlying spatial stochastic process.\n",
    "\n",
    "**Arbitrary Points**\n",
    "\n",
    "The second type of point we consider are those locations where the phenomena of interest has not been observed. These go by various names such as \"empty space\" or \"regular\" points, and at first glance might seem less interesting to a spatial analayst. However, these types of points play a central role in a class of point pattern methods that we explore below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Exploring first-order properties**\n",
    "\n",
    "Estimate how intensity of point pattern varies over an area (Quadrat analysis, kernel estimation)\n",
    "\n",
    "**Exploring second-order properties**\n",
    "\n",
    "Estimate the presence of spatial dependence among events (Nearest neighbor distances, K-function)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complete spatial randomness**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CSR assumes that points follow a homogeneous Poisson process over the study area\n",
    "- the density of points is constant (homogeneous) over the study area\n",
    "- For a random sample of subregions, the frequency distribution of the number of points in each region will follow a Poisson distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pysal package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods of Point Pattern Analysis in PySAL\n",
    "\n",
    "The points module in PySAL implements basic methods of point pattern analysis organized into the following groups:\n",
    "\n",
    "- Point Processing\n",
    "- Centrography and Visualization\n",
    "- Quadrat Based Methods\n",
    "- Distance Based Methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libpysal as ps\n",
    "import numpy as np\n",
    "from pointpats import PointPattern\n",
    "import pandas as pd\n",
    "import contextily\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our own point pattern. Therefor we can for example use a list of coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = [[66.22, 32.54], [22.52, 22.39], [31.01, 81.21],\n",
    "          [9.47, 31.02],  [30.78, 60.10], [75.21, 58.93],\n",
    "          [79.26,  7.68], [8.23, 39.93],  [98.73, 77.17],\n",
    "          [89.78, 42.53], [65.19, 92.08], [54.46, 8.48]]\n",
    "p1 = PointPattern(points)\n",
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.mbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(p1.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(p1.points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we can create point pattern also from numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(p1.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_np = PointPattern(points)\n",
    "p1_np.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires = pd.read_csv('Data/non-spatial/nigeria_fires.csv')\n",
    "geometry = [Point(xy) for xy in zip(fires.LONGITUDE,fires.LATITUDE)]\n",
    "crs = {'init': 'epsg:2263'}\n",
    "gdf = gpd.GeoDataFrame(fires, crs=crs, geometry=geometry)\n",
    "gdf_fires = gdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp= PointPattern(gdf,names= gdf.columns)\n",
    "pp.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_fires.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.plot(window=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"x\", y=\"y\", data=pp.df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplleaflet\n",
    "win = gpd.read_file('Data/vector/fires/nigeria.shp')\n",
    "ax = gdf_fires.plot()\n",
    "win.to_crs('EPSG:4326').plot(ax=ax)\n",
    "mplleaflet.display(fig=ax.figure, tiles='cartodb_positron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to define the real extent of our point pattern, we can also add a so called window, this window can be\n",
    "\n",
    "- a rectangle;\n",
    "- a polygon or polygons, with polygonal holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pointpats import Window\n",
    "import geopandas as gpd\n",
    "win.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = win.geometry[0].exterior.coords.xy\n",
    "window = Window(list(zip(x,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp= PointPattern(gdf, window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.plot(window=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Random**: any point in the point pattern is equally likely to occur at any location. The location of any point is not affected by the location of any other point\n",
    "- **Uniform**: every point inside the observed area is as far away from all of its neighbors as possible\n",
    "- **Clustered**: points are concentrated close together\n",
    "\n",
    "<img src=\"images/pointpattern.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random point patterns are the outcome of CSR. CSR has two major characteristics:\n",
    "1. Uniform: each location has equal probability of getting a point (where an event happens)\n",
    "2. Independent: location of event points are independent\n",
    "\n",
    "It usually serves as the null hypothesis in testing whether a point pattern is the outcome of a random process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustered Patterns are more grouped than random patterns. Visually, we can observe more points at short distances. There are two sources of clustering:\n",
    "\n",
    "- Contagion: presence of events at one location affects probability of events at another location (correlated point process)\n",
    "- Heterogeneity: intensity 𝜆 varies with location (heterogeneous Poisson point process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulating CSR** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pointpats import PoissonPointProcess\n",
    "\n",
    "np.random.seed(5)\n",
    "samples = PoissonPointProcess(pp.window, pp.n, 1, conditioning=True, asPP=False)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.realizations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a point pattern from the simulated point series\n",
    "pp_csr = PointPattern(samples.realizations[0], window=window)\n",
    "pp_csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_csr.plot(window= True,title='Random Point Pattern')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centrography refers to a set of descriptive statistics that provide summary descriptions of point patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/centrography.svg\" />\n",
    "Source: https://mgimond.github.io/Spatial/point-pattern-analysis.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the pointpats package you can find several functions for centrography including\n",
    "\n",
    "**Central Tendency**\n",
    "- mean_center: calculate the mean center of the unmarked point pattern.\n",
    "- weighted_mean_center: calculate the weighted mean center of the marked point pattern.\n",
    "- manhattan_median: calculate the manhattan median\n",
    "- euclidean_median: calculate the Euclidean median\n",
    "    \n",
    "**Dispersion and Orientation**\n",
    "- std_distance: calculate the standard distance\n",
    "\n",
    "**Shape Analysis**\n",
    "- hull: calculate the convex hull of the point pattern\n",
    "- mbr: calculate the minimum bounding box (rectangle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Central Tendency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Central tendency is often used when we are concerned about the center of our spatial point pattern. Several approaches can be used to measure central tendencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pointpats.centrography import hull, mbr, mean_center, weighted_mean_center, manhattan_median, std_distance,euclidean_median,ellipse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean center**\n",
    "\n",
    "$$x_{mc}=\\frac{1}{n} \\sum^n_{i=1}x_i$$\n",
    "$$y_{mc}=\\frac{1}{n} \\sum^n_{i=1}y_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = mean_center(pp.points)\n",
    "mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.plot()\n",
    "plt.plot(mc[0], mc[1], 'b^', color='red', label='Mean Center')\n",
    "plt.legend(numpoints=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Mean Center $(x_{wmc},y_{wmc})$\n",
    "\n",
    "$$x_{wmc}=\\sum^n_{i=1} \\frac{w_i x_i}{\\sum^n_{i=1}w_i}$$\n",
    "$$y_{wmc}=\\sum^n_{i=1} \\frac{w_i y_i}{\\sum^n_{i=1}w_i}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted mean center is usefull wehn we are working with marked point pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pp.df['dn'] = pd.Categorical(pp.df['DAYNIGHT'])\n",
    "pp.df['weights'] = pp.df.dn.cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pp.df['weights'].to_numpy()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmc = weighted_mean_center(pp.points, weights)\n",
    "wmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.plot() #use class method \"plot\" to visualize point pattern\n",
    "plt.plot(mc[0], mc[1], 'b^', label='Mean Center') \n",
    "plt.plot(wmc[0], wmc[1], 'gd', label='Weighted Mean Center')\n",
    "plt.legend(numpoints=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Mean Center $(x_{wmc},y_{wmc})$\n",
    "\n",
    "The Manhattan median is the center location where the absolute distance to all points is minimized.\n",
    "\n",
    "$$min  f(x_{mm},y_{mm})= \\sum^n_{i=1}(|x_i-x_{mm}|+|y_i-y_{mm}|)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = manhattan_median(pp.points)\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.plot()\n",
    "plt.plot(mc[0], mc[1], 'b^', label='Mean Center')\n",
    "plt.plot(wmc[0], wmc[1], 'gd', label='Weighted Mean Center')\n",
    "plt.plot(mm[0], mm[1], 'rv', label='Manhattan Median')\n",
    "plt.legend(numpoints=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Euclidean Median describes the location from which the sum of the Euclidean distances to all points in a distribution is a minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$min  f(x_{em},y_{em})= \\sum^n_{i=1} \\sqrt{(x_i-x_{em})^2+(y_i-y_{em})^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em = euclidean_median(pp.points)\n",
    "em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.plot()\n",
    "plt.plot(mc[0], mc[1], 'b^', label='Mean Center')\n",
    "plt.plot(wmc[0], wmc[1], 'gd', label='Weighted Mean Center')\n",
    "plt.plot(mm[0], mm[1], 'rv', label='Manhattan Median')\n",
    "plt.plot(em[0], em[1], 'm+', label='Euclidean Median')\n",
    "plt.legend(numpoints=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Distance & Standard Distance Circle\n",
    "The Standard distance provides a measure of how dispersed the events are around their mean center. \n",
    "\n",
    "$$SD = \\displaystyle \\sqrt{\\frac{\\sum^n_{i=1}(x_i-x_{m})^2}{n} + \\frac{\\sum^n_{i=1}(y_i-y_{m})^2}{n}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdd = std_distance(pp.points)\n",
    "stdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circle1=plt.Circle((mc[0], mc[1]),stdd,color='r')\n",
    "ax = pp.plot(get_ax=True, title='Standard Distance Circle')\n",
    "ax.add_artist(circle1)\n",
    "plt.plot(mc[0], mc[1], 'b^', label='Mean Center')\n",
    "ax.set_aspect('equal')\n",
    "plt.legend(numpoints=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sx, sy, theta = ellipse(pp.points)\n",
    "sx, sy, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_degree = np.degrees(theta) #need degree of rotation to plot the ellipse\n",
    "theta_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "from pylab import figure, show,rand\n",
    "fig = figure()\n",
    "#ax = fig.add_subplot(111, aspect='equal')\n",
    "e = Ellipse(xy=mean_center(pp.points), width=sx*2, height=sy*2, angle=-theta_degree) #angle is rotation in degrees (anti-clockwise)\n",
    "ax = pp.plot(get_ax=True, title='Standard Deviational Ellipse')\n",
    "ax.add_artist(e)\n",
    "e.set_clip_box(ax.bbox)\n",
    "e.set_facecolor([0.8,0,0])\n",
    "e.set_edgecolor([1,0,0])\n",
    "\n",
    "plt.plot(mc[0], mc[1], 'b^', label='Mean Center')\n",
    "plt.legend(numpoints=1)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density based analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A point pattern can be thought of as a “realization” of an underlying process whose intensity λ is estimated from the observed point pattern’s density. Density measurements can be broken down into two categories: \n",
    "- global: simply the ratio of observed number of points to the study region’s surface area \n",
    "\n",
    "- local: measures density at different locations within the study area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### global density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intensity of a point process at point $si$ can be defined as:\n",
    "\n",
    "$$\\lambda(s_j) = \\lim \\limits_{|\\mathbf{A}s_j| \\to 0} \\left \\{ \\frac{E(Y(\\mathbf{A}s_j)}{|\\mathbf{A}s_j|} \\right \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf|{A}s_j|$: area of region {A}s_j\n",
    "\n",
    "$E(Y(\\mathbf{A}s_j)$: expected event points in {A}s_j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PySAL, the intensity is estimated by using a geometric object to encode the study region, also called window. So basically divide the number of our point events by the area of our window. This can be for example the minimum bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.lambda_mbb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or the convex hull of the point pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.lambda_mbb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we just look at the global density we may loose information on the spatial patterns of the point distribution. Therefor we will also look at the local density.One way to do this is to use the quadrat count.The quadrat density is calculated by dividing the study area into multiple sub-regions. The density is than computed for each quadrat by dividing the number of points in each quadrat by the quadrat’s area.\n",
    "\n",
    "We can assume that if the underlying process is a CSR process, the expected number of points inside a sub-region of area $|A|$ should be $\\lambda |A|$ ($\\lambda$ is the intensity which is uniform across the study area for a CSR). If we now overlay multiple subregions over the window area we can easily calculate the expected number of points inside each subregion under the null of CSR and compare the observed point counts against the expected counts. Then we can calculate a 𝜒2 test statistic and see if the nullhypotheses (point pattern is the outcome of a random proces) can be rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pointpats.quadrat_statistics as qs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's impose 6x6 rectangles over our point pattern window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.plot(window=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_r = qs.QStatistic(pp,shape= \"rectangle\",nx = 6, ny = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_r.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_r.chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_r.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_r.chi2_pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for our simulated CRS point pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_r = qs.QStatistic(pp_csr,shape= \"rectangle\",nx = 6, ny = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_r.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_r.chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_r.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_r.chi2_pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernel density, like the quadrat density, is used to compute the local density at smaller sub-regions of our study site. But unlike the quadrat density, it uses a moving window approach overlap results in a overlap between the subregions. The result is raster in which each cell gets the density value computed for the kernel window centered on that cell.\n",
    "\n",
    "The most basic kernel would be a rectengular window covering for example 3x3 cells. The window moves of the raster cell by cell and assigns the mean value of all 9 cells to the cell in the center. In this case all cells in the window have equal weights. \n",
    "\n",
    "In many cases, weights are assigned to the window in form of a kernel function. For example the gaussian kernel function assigns weights to the window that are inversely proportional to their distances to the kernel window center, which produces a smoother density map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "f, ax = plt.subplots(1, figsize=(9, 9))\n",
    "sns.kdeplot(pp.df['x'], pp.df['y'],\n",
    "                n_levels=50, shade=True,\n",
    "                alpha=0.55, cmap='viridis_r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(pp.df.x, pp.df.y, kind='kde', color=\"skyblue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance based approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to the density based methods are the distance based methods. The idea is to investigate how the points are distributed relative to one another (second-order properties). For example if we want to now of the location of deadwood in a rejuvinating forest will be influencing the location of juvenile trees. If this is the case we would assume a to identify patterns of small clustered trees around the deadwood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Nearest Neighbor Distance Statistics\n",
    "\n",
    "The nearest neighbor(s) for a point $u$ is the point(s) $N(u)$ which meet the condition\n",
    "$$d_{u,N(u)} \\leq d_{u,j} \\forall j \\in S - u$$\n",
    "\n",
    "The distance between the nearest neighbor(s) $N(u)$ and the point $u$ is nearest neighbor distance for $u$. After searching for nearest neighbor(s) for all the points and calculating the corresponding distances, we are able to calculate mean nearest neighbor distance by averaging these distances.\n",
    "\n",
    "It was demonstrated by Clark and Evans(1954) that mean nearest neighbor distance statistics distribution is a normal distribution under null hypothesis (underlying spatial process is CSR). We can utilize the test statistics to determine whether the point pattern is the outcome of CSR. If not, is it the outcome of cluster or regular\n",
    "spatial process?\n",
    "\n",
    "Mean nearest neighbor distance statistic\n",
    "\n",
    "$$\\bar{d}_{min}=\\frac{1}{n} \\sum_{i=1}^n d_{min}(s_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the average first nearest neighbor distance set k=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.knn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two nearest neighbors\n",
    "pp.knn(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.max_nnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.min_nnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.mean_nnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.nnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(pp.nnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor Distance Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearest neighbour distance distribution functions of a point process are cumulative distribution functions. By comparing the distance function of the observed point pattern with that of the point pattern from a CSR process, we are able to infer whether the underlying spatial process of the observed point pattern is CSR or not for a given confidence level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G function - event-to-event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function, Ripley's G function, focuses on the distribution of nearest neighbor distances. That is, the G function summarises the distances between each point in the point pattern to their nearest neighbor in the pattern.\n",
    "\n",
    "The idea is that \"clusterd\" point pattern should have more closer points than a \"dispersed\" pattern while a completely random pattern should have something in between. So if the G function increases rapidly with distance, we probably have a clustered pattern and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the G function for our point pattern and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pointpats import  K,L,G,F, Genv, Fenv, Jenv, Kenv, Lenv\n",
    "\n",
    "gp1 = G(pp, intervals=20)\n",
    "gp1.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to determine if our calculated G-function for our point pattern derivates significantly from a random ditribution, we calculate the simulation envelope. Therefor we simulate CSR a lot of times, say 1000 times. Then, we can calculate the function for each simulated point pattern. For every distance d, we sort the function values of the 1000 simulated point patterns. Given a confidence level, say 95%, we can acquire the 25th and 975th value for every distance d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realizations = PoissonPointProcess(pp.window, pp.n, 100, asPP=True) # simulate CSR 100 times\n",
    "genv = Genv(pp, intervals=20, realizations=realizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates=pp.df[['x','y']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,2,figsize=(13,5), \n",
    "                    gridspec_kw=dict(width_ratios=(6,3)))\n",
    "\n",
    "ax[0].fill_between(genv.d, genv.low, genv.high, alpha=.5, \n",
    "                 label='95% of simulations')\n",
    "\n",
    "ax[0].plot(genv.d, genv.mean, color='cyan', \n",
    "         label='mean of simulations')\n",
    "\n",
    "ax[0].plot(*genv.observed.T,\n",
    "         label = 'observed', color='red')\n",
    "\n",
    "ax[0].set_xlabel('distance')\n",
    "ax[0].set_ylabel('% of nearest neighbor\\ndistances shorter')\n",
    "ax[0].legend()\n",
    "ax[0].set_title(r\"Ripley's $G(d)$ function\")\n",
    "ax[1].scatter(*coordinates.T)\n",
    "ax[1].set_xticks([])\n",
    "ax[1].set_yticks([])\n",
    "ax[1].set_xticklabels([])\n",
    "ax[1].set_yticklabels([])\n",
    "ax[1].set_title('Pattern')\n",
    "f.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-function - \"point-event\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to measure dispersion is to examine the gaps in the pattern usinf the F-Function.  The F-function works by analyzing the distance to points in the pattern from locations in empty space. If the our pattern has large gaps or empty areas, the F function will increase slowly. But, if the pattern is highly dispersed, then the F function will increase rapidly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp1 = F(pp, intervals=20)\n",
    "fp1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp1.plot(qq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fenv = Fenv(pp, intervals=40, realizations=realizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,2,figsize=(9,3), \n",
    "                    gridspec_kw=dict(width_ratios=(6,3)))\n",
    "\n",
    "# plot the middle 95% \n",
    "ax[0].fill_between(fenv.d, fenv.low, fenv.high, alpha=.5, \n",
    "                 label='95% of simulations')\n",
    "\n",
    "# show the average of simulations\n",
    "ax[0].plot(fenv.d, fenv.mean, color='cyan', \n",
    "         label='mean of simulations')\n",
    "\n",
    "# and the observed pattern's G function\n",
    "ax[0].plot(*fenv.observed.T,\n",
    "         label = 'observed', color='red')\n",
    "\n",
    "# clean up labels and axes\n",
    "ax[0].set_xlabel('distance')\n",
    "ax[0].set_ylabel('% of nearest neighbor\\ndistances shorter')\n",
    "ax[0].set_title(r\"Ripley's $F(d)$ function\")\n",
    "ax[0].legend()\n",
    "\n",
    "# plot the pattern itself on the next frame\n",
    "ax[1].scatter(*coordinates.T)\n",
    "\n",
    "# and clean up labels and axes there, too\n",
    "ax[1].set_xticks([])\n",
    "ax[1].set_yticks([])\n",
    "ax[1].set_xticklabels([])\n",
    "ax[1].set_yticklabels([])\n",
    "ax[1].set_title('Pattern')\n",
    "f.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interevent distance functions\n",
    "\n",
    "Nearest neighbor distance functions consider only the nearest neighbor distances. The problem with this approach is, that distances to higher order neigbours a ignored. Interevent distance functions, including K and L functions, are proposed to consider distances between all pairs of event points.\n",
    "\n",
    "K-,L- and pair correlation function allow us to investigate changes in the surrounding structure of a point with increasing distance from its position. The K function, is used to measure counts, rather than distances. The K function measures the count of points in the pattern within a circle of increasing radius. Patterns with clustering will exhibit a steep rise, whereas patterns with dispersion will exhibit a much slower rise. As before, we can compute a \"reference\" using simulations based on a completely spatially random process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp1 = K(pp)\n",
    "kp1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kenv = Kenv(pp, intervals=40, realizations=realizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,2,figsize=(9,3), \n",
    "                    gridspec_kw=dict(width_ratios=(6,3)))\n",
    "ax[1].scatter(*coordinates.T)\n",
    "ax[0].fill_between(kenv.d, kenv.low, kenv.high, alpha=.5, \n",
    "                 label='95% of simulations')\n",
    "ax[0].plot(kenv.d, fenv.mean, color='cyan', \n",
    "         label='mean of simulations')\n",
    "ax[0].plot(*kenv.observed.T,\n",
    "         label = 'observed', color='red')\n",
    "ax[0].set_xlabel('distance')\n",
    "ax[0].set_ylabel('% of nearest neighbor\\ndistances shorter')\n",
    "ax[0].legend()\n",
    "ax[1].set_xticks([])\n",
    "ax[1].set_yticks([])\n",
    "ax[1].set_xticklabels([])\n",
    "ax[1].set_yticklabels([])\n",
    "ax[1].set_title('Pattern')\n",
    "ax[0].set_title(r\"Ripley's $K(d)$ function\")\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L-function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to several advantages the L-function is often used instead of Ripley’s K-function.\n",
    "It is often easier to interpret due to its linearized and normalized form. Positive deviation from the angle bisector indicates clustering, whilst negative deviation indicates regularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp1 = L(pp_csr, )\n",
    "lp1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kenv = Lenv(pp, intervals=40, realizations=realizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,2,figsize=(9,3), \n",
    "                    gridspec_kw=dict(width_ratios=(6,3)))\n",
    "ax[1].scatter(*coordinates.T)\n",
    "ax[0].fill_between(kenv.d, kenv.low, kenv.high, alpha=.5, \n",
    "                 label='95% of simulations')\n",
    "ax[0].plot(kenv.d, fenv.mean, color='cyan', \n",
    "         label='mean of simulations')\n",
    "ax[0].plot(*kenv.observed.T,\n",
    "         label = 'observed', color='red')\n",
    "ax[0].set_xlabel('distance')\n",
    "ax[0].set_ylabel('% of nearest neighbor\\ndistances shorter')\n",
    "ax[0].legend()\n",
    "ax[1].set_xticks([])\n",
    "ax[1].set_yticks([])\n",
    "ax[1].set_xticklabels([])\n",
    "ax[1].set_yticklabels([])\n",
    "ax[1].set_title('Pattern')\n",
    "ax[0].set_title(r\"Ripley's $K(d)$ function\")\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the techniques we used above we were able to characterize whether point patterns are dispersed or clustered in space. We now know that our point pattern is clustered , but knowing that a point pattern is clustered does not necessarily give us information about where that cluster are. There multiple ways to identify clusters in point pattern. In this case, we will use the dbscan algorithm from the scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs, lbls = dbscan(pp.df[['x', 'y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls = pd.Series(lbls, index=pp.df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(9, 9))\n",
    "noise = pp.df.loc[lbls==-1, ['x', 'y']]\n",
    "ax.scatter(noise['x'], noise['y'], c='grey', s=5, linewidth=0)\n",
    "ax.scatter(pp.df.loc[pp.df.index.difference(noise.index), 'x'], \\\n",
    "           pp.df.loc[pp.df.index.difference(noise.index), 'y'], \\\n",
    "          c='red', linewidth=0)\n",
    "mplleaflet.display(fig=ax.figure, tiles='cartodb_positron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pysal.org/\n",
    "\n",
    "https://geographicdata.science/book/\n",
    "\n",
    "https://mgimond.github.io/Spatial/point-pattern-analysis.html\n",
    "\n",
    "spatstat: AnRPackage for Analyzing Spatial PointPatterns\n",
    "\n",
    "Baddeley, A., E. Rubak, and R. Turner. 2015. Spatial Point Patterns: Methodology and Applications with R Boca Raton, FL: Chapman & Hall/CRC Press\n",
    "\n",
    "Diggle, P. (2014). Spatial Point Pattern. In M. Lovric (Ed.), International Encyclopedia\n",
    "of Statistical Science, pp. 1361–1363. Springer Berlin Heidelberg.\n",
    "\n",
    "Perry, G. L. W., B. P. Miller, and N. J. Enright (2006). A comparison of methods for the\n",
    "statistical analysis of spatial point patterns in plant ecology. Plant Ecology 187 (1),\n",
    "59–82.\n",
    "\n",
    "Ripley, B. D. (1988). Statistical Inference for Spatial Processes. Cambridge: Cambridge University Press. doi: 10.1017/CBO9780511624131"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
